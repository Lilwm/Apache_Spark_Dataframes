{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwmuHasx9Rf6RqiKGi63aj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lilwm/Apache_Spark_Dataframes/blob/main/Spark_SQL_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a Data professional, you need to perform an analysis by answering questions about\n",
        "some stock market data on Safaricom from the years 2012-2017.\n"
      ],
      "metadata": {
        "id": "hKjzEmdADz8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Data Importation and Exploration\n",
        "\n",
        "* Start a spark session and load the stock file while inferring the data types\n",
        "Determine the column names\n",
        "* Make observations about the schema.\n",
        "* Show the first 5 rows\n",
        "* Use the describe method to learn about the data frame\n",
        "\n"
      ],
      "metadata": {
        "id": "bWGjosGaD6vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Start a spark session and load the stock file while inferring the data types.\n",
        "!pip install pyspark\n",
        "\n",
        "#Determine the column names\n",
        "#Make observations about the schema.\n",
        "#Show the first 5 rows\n",
        "#Use the describe method to learn about the data frame\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcxcadZSEGHr",
        "outputId": "669dce1e-07e4-45eb-90f6-4f3024e504da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=806f54d62246e19d1b9b481efc8fcbc776e677e10209869c3f9f2d557830e009\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run a spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"ReadCSV\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "tkr0nuP8E7fr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data exploration\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "df = spark.read.csv(\"saf_stock.csv\", header=True, inferSchema=True)\n",
        "# Determine the column names\n",
        "print(f\" Column Names : {df.columns} \\n \\n\")\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AfINEBfFlvk",
        "outputId": "ca69c667-d5c4-4983-d0ac-4cd5d8d08c1d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Column Names : ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'] \n",
            " \n",
            "\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|               Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03 00:00:00|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04 00:00:00|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05 00:00:00|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06 00:00:00|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09 00:00:00|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make observations about the schema.\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kDdACusbJ2a",
        "outputId": "6158f631-dcd5-4e5c-bfc2-c55471e543bc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: timestamp (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data has *integer, double and timestamp* values"
      ],
      "metadata": {
        "id": "XlUi5T6Pc3ON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first five  contents of the DataFrame\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI47xC9sc1dW",
        "outputId": "f7646d0c-0a55-4e0d-a9bd-2e513ec0840f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|               Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03 00:00:00|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04 00:00:00|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05 00:00:00|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06 00:00:00|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09 00:00:00|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Use the describe method to learn about the data frame\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWEGGx3AI2Jy",
        "outputId": "67ca6e0e-a2fd-432f-cc93-a1ec86065413"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation\n",
        "* Format all the data to 2 decimal places i.e. format_number()\n",
        "* Create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "High Price versus volume of stock traded for a day\n"
      ],
      "metadata": {
        "id": "TEY6FUVWR1Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#format data to two dp\n",
        "\n",
        "#import necessary libraries\n",
        "from pyspark.sql.functions import round, col\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "for col_name, col_type in df.dtypes:\n",
        "    if col_type in ('double', 'float'):\n",
        "        df = df.withColumn(col_name, F.round(col_name, 2))  #round to 2 dp\n",
        "#confirm the data is in 2dp\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re-thidrR6AD",
        "outputId": "ed2087a4-577f-4016-9983-0390cbcbde61"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-----+-----+-----+--------+---------+\n",
            "|               Date| Open| High|  Low|Close|  Volume|Adj Close|\n",
            "+-------------------+-----+-----+-----+-----+--------+---------+\n",
            "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12668800|    52.62|\n",
            "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9593300|    52.08|\n",
            "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12768200|    51.83|\n",
            "|2012-01-06 00:00:00|59.42|59.45|58.87| 59.0| 8069400|    51.46|\n",
            "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6679300|    51.62|\n",
            "+-------------------+-----+-----+-----+-----+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, format_number\n",
        "\n",
        "# create a new column called \"HV Ratio\" that is the ratio of the High Price versus volume of stock traded for a day\n",
        "new_df = df.withColumn(\"HV Ratio\", col(\"High\") / col(\"Volume\"))\n",
        "\n",
        "# print the updated data frame\n",
        "new_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwCqJg35d9GP",
        "outputId": "7b5556d4-7879-43b6-a24c-d5ddbf596610"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-----+-----+-----+--------+---------+--------------------+\n",
            "|               Date| Open| High|  Low|Close|  Volume|Adj Close|            HV Ratio|\n",
            "+-------------------+-----+-----+-----+-----+--------+---------+--------------------+\n",
            "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12668800|    52.62|4.819714574387472E-6|\n",
            "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9593300|    52.08|6.290848821573389...|\n",
            "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12768200|    51.83|4.669413073103491E-6|\n",
            "|2012-01-06 00:00:00|59.42|59.45|58.87| 59.0| 8069400|    51.46|7.367338339901356E-6|\n",
            "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6679300|    51.62|8.915604928660188E-6|\n",
            "+-------------------+-----+-----+-----+-----+--------+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis\n",
        "* What day had the Peak High in Price?\n",
        "* What is the mean of the Close column?\n",
        "* What is the max and min of the Volume column?\n",
        "* How many days was the Close lower than 60 dollars?\n",
        "* What percentage of the time was the High greater than 80 dollars?\n",
        "* What is the Pearson correlation between High and Volume?\n",
        "* What is the max High per year?\n",
        "* What is the average Close for each Calendar Month?"
      ],
      "metadata": {
        "id": "gtltKNM9gALm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# register RDD as a temporary table\n",
        "from pyspark.sql import SQLContext\n",
        "sqlCtx = SQLContext(sc)\n",
        "\n",
        "new_df.createOrReplaceTempView('saf_stock')\n",
        "tables = sqlCtx.tableNames()\n",
        "print(tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7MCdBufgJyM",
        "outputId": "119eba5c-6bc6-4648-ebf6-7bdf57fa7f6d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['saf_stock']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what day had peak high price?\n",
        "sqlCtx.sql('select date, High from saf_stock order by High desc').show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS0TXoVghHa2",
        "outputId": "6f02f22a-6349-4cf3-c131-c4642cbfcb91"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+\n",
            "|               date| High|\n",
            "+-------------------+-----+\n",
            "|2015-01-13 00:00:00|90.97|\n",
            "+-------------------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is the mean of the Close column?\n",
        "\n",
        "sqlCtx.sql('SELECT AVG(Close) AS avg_close FROM saf_stock').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N252Xu5iPx7",
        "outputId": "bfb7d888-e4dd-4e7e-e1ba-a3d324a965bf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|        avg_close|\n",
            "+-----------------+\n",
            "|72.38844992050863|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the max and min of the Volume column?\n",
        "sqlCtx.sql('SELECT MIN(Volume) AS min_vol, MAX(Volume) AS max_vol FROM saf_stock').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yRfl-Oyjf5r",
        "outputId": "9a1a2d45-3ddf-4539-da79-bac995ef6252"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|min_vol| max_vol|\n",
            "+-------+--------+\n",
            "|2094900|80898100|\n",
            "+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many days was the Close lower than 60 dollars?\n",
        "sqlCtx.sql('SELECT COUNT(Close) as close_below60 FROM saf_stock WHERE Close < 60').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jwW2NV1kKfS",
        "outputId": "7e9ca6fb-e19e-4353-ac9b-2a91adf310f7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|close_below60|\n",
            "+-------------+\n",
            "|           81|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What percentage of the time was the High greater than 80 dollars?\n",
        "query ='SELECT (SELECT COUNT(High) FROM saf_stock where High > 80)*100/(select COUNT(High) from saf_stock) as Percentage  From saf_stock group by Percentage'\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXlE-L_KlBUK",
        "outputId": "b0210a9e-11d8-4cca-b27b-bdcb810d489b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       Percentage|\n",
            "+-----------------+\n",
            "|9.141494435612083|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the Pearson correlation between High and Volume?\n",
        "from pyspark.sql.functions import corr\n",
        "pearson_corr = new_df.select(corr(\"High\", \"Volume\").alias(\"correlation\")).collect()[0][0]\n",
        "pearson_corr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzmOqGtsmOHa",
        "outputId": "15d403a2-003f-4849-c3d0-703af4663133"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.33843260582148915"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the max High per year?\n",
        "sqlCtx.sql(\"SELECT year(Date) as year, max(High) as Max_High FROM saf_stock GROUP BY year(Date) ORDER BY Max_High DESC\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b4-2i2Rm0KA",
        "outputId": "395938aa-744c-4ff6-c459-3c5e3a6165f4"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+\n",
            "|year|Max_High|\n",
            "+----+--------+\n",
            "|2015|   90.97|\n",
            "|2014|   88.09|\n",
            "|2013|   81.37|\n",
            "|2012|    77.6|\n",
            "|2016|   75.19|\n",
            "+----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the average Close for each Calendar Month?\n",
        "sqlCtx.sql('select MONTH(Date), AVG(Close) as monthly_average from saf_stock group by MONTH(Date) order by MONTH(Date) asc').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZQ5wc1unYMK",
        "outputId": "380869d8-65e4-4650-8a96-a91758391cf7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+\n",
            "|month(Date)|  monthly_average|\n",
            "+-----------+-----------------+\n",
            "|          1|71.44801980198022|\n",
            "|          2|71.30680412371134|\n",
            "|          3|71.77794392523363|\n",
            "|          4|72.97361904761907|\n",
            "|          5|72.30971698113206|\n",
            "|          6|72.49537735849057|\n",
            "|          7|74.43971962616824|\n",
            "|          8|73.02981818181819|\n",
            "|          9|72.18411764705883|\n",
            "|         10|71.57854545454546|\n",
            "|         11|72.11108910891085|\n",
            "|         12|72.84792452830189|\n",
            "+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}